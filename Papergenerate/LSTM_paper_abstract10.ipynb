{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Recurrent Neural Network\n",
    "- Mimicing Shakespeare's writing style\n",
    "- Long short-term memory(LSTM)\n",
    "\n",
    "![alt text](./LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 1\n",
    "lr = 0.002\n",
    "NUM_STEPS = 500\n",
    "DATA_PATH = './data/abstract10.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('num_chars = ', n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_encode(text, vocab):\n",
    "    return [vocab.index(x) + 1 for x in text if x in vocab]\n",
    "\n",
    "\n",
    "def vocab_decode(array, vocab):\n",
    "    return ''.join([vocab[x - 1] for x in array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = (\" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 3042870\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open(DATA_PATH).read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    text = re.sub('[^\\w ]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = file.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions for text processing\n",
    "### 1) Random Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2580277\n",
      "ents by a large margin. \n",
      "Abstract We present an effective method for supervised feature construction. The main goal of the approach is to construct a feature representation for which a set of linear hy\n"
     ]
    }
   ],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    print(start_index)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      " 37\n",
      " 38\n",
      " 13\n",
      " 14\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 6 (GPU 4)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor).cuda(4)\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      " 37\n",
      " 38\n",
      " 13\n",
      " 14\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 6 (GPU 4)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def char_tensor2(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        print(string[c])\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor).cuda(4)\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Chunk into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size,hidden_size,num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input, hidden,cell):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden,cell\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(num_layers,batch_size,hidden_size)).cuda(4)\n",
    "        cell = Variable(torch.zeros(num_layers,batch_size,hidden_size)).cuda(4)\n",
    "        return hidden,cell\n",
    "model = RNN(n_characters, hidden_size, n_characters, num_layers).cuda(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      "[torch.cuda.LongTensor of size 1 (GPU 4)]\n",
      "\n",
      "torch.Size([1, 1, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "inp = char_tensor(\"A\")\n",
    "print(inp)\n",
    "hidden,cell = model.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "out,hidden,cell = model(inp,hidden,cell)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"A\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(500):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "        print(predicted_char,end=\"\")\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Variable containing:\n",
      " 1.8308\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract For and such as combine a novels algorithmative responed large problems by an eline singment wo simal and by lides We provide in classive learning and an accorcements diverse of signal by progongly sequirficientially perifiers or nonlineling ne linear solding distriby behat intervades is a selectation a set oreconsteptial feach partictorithmic problem of componet velary where there processed now for spectors analyze ingelly recomplex on eveloped in stoching the larges classificatior stud\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.0629\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract Stattory in Bayesian oitted computer based in learning empirations pocess which this kernelly decomenting popuse that approach the many posting We propose and the how a naminmand by application of data example learning the problems has poneral that diverge on LM a learning and novel selective now norcural learning apprial to the high approach the application providic Nejong and models that the soown of empormant stask of and of novel Wisk from intropoing is are of monsted as approseart v\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.2497\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We propsed tasks when the used set estimating a restarkely statistical learning the gynes is opition additing dof classifeation on problem of a represent as hiverize general to deterning sammont noise to de cluster of cam we and learnining Cas anfulluacting the regase a generally concoiner work low regrable learning somes computing functionalyze moting Case with the combinem to highdes using these of reormal of LAL algorithms This framenoring quemility sets on the convexal counce as the \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.1979\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We consider tasks general approation the algoric distributed to tamene of synitions that modeling halbased reconstritable fact Markov for theiphitational network of a method and ven training compute recent proposed the densition of theirkewn we and explorive unowe candentific such as to of approach compicty stochastic by problems are application models and statistic product demonstrating and the function the multiple and algorithms in such the algorithm robasing explosed setting a conveo\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.6275\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We pressimization and proposetic to convote is how representeration and as recognition an intradied to the probabilisteration of additation which reclosupefficient to the problem are However of classifficided proputions bone a novel difficlew and approaches SPCLC approach which Direcently for learning show in algorithm statistric to distribution There optimization using the relation for setting natural becoved for statistically of the becosted as of the nown a method sparse in scalt The \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.0523\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract To paper space for to sequence latential methodality use consing parametric generalizational for viven provide computing subse We introduce of a sociond of model we sementation in relation from of a positient sequenting variants Maronges is such rance that collopencifored parameterate a setts that tass of model for analyse complexation highdimension of natural computing hiew interpering in orleous ant nondmet in spaces Can a studied introduce can be on labele differeng is computies in th\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.3113\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract The paper decestization oderent rensoryzation in the rethod the framework this paper formpling variablemistic Provide stroochasting the spardence over simmel from orling such a sequent from interestic many SCTLB prection in a noties Inference both the problems asso topic models of the task of partitions we kecent discremely the featuress the fiels is of a stension K Sproduction is exposts in contineration with continfor besurks gradiention in the learning which and a new a variation desc\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.1508\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We present neurous of problem has processes to eveluration problem is the graph the dynamitions in the convex extric instramplemulabing receneral be about and a twocable study explorbased bandit are to of a meased of prement Sk the modele variable to the contive problems In inclusically invodrages contreling proputer Processes of perparamently and importic linear anary introduce of Stratistic matrix communily of processing exweme and if strite of problem of a general to applications comp\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.3310\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We predictions are piges to seconsing state consistsoreare a system enset of that regularized for learning to the grame from the the has been complex natural onpited on is a large studient set over clist relaterized from parcits of models combination based The denstimistic atrigs object parentation of approximizate at clustering search is the problems the an action is sperampled onterond algorithms a a proximization of rewach enstarcul solvinual set such questic an that random as the pro\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.6310\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We provide to simul orpiner computer whan the conveolutional calreing in this input as the sequences that steates models to have classes The delices with is bandit the function had loowhads that take the continat for not object mephods a new to be detector deendes as in the the dequences structuart the generalized in a natural matrix functions on realworithms Given with the high PPP Many on the lategul difference on the convalue the process Gaussian showver potion on the consider to opti\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(cleaner(aa[random.randint(0,len(aa))]))\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden,cell = model.init_hidden()\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y,hidden,cell = model(x,hidden,cell)\n",
    "        loss += loss_func(y,y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
