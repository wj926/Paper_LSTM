{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Recurrent Neural Network\n",
    "- Abstract\n",
    "- Long short-term memory(LSTM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings\n",
    "### 1) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "chunk_len = 200\n",
    "hidden_size = 100\n",
    "batch_size =1\n",
    "num_layers = 1\n",
    "lr = 0.002\n",
    "NUM_STEPS = 500\n",
    "DATA_PATH = './data/abstract.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 1) Prepare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_encode(text, vocab):\n",
    "    return [vocab.index(x) + 1 for x in text if x in vocab]\n",
    "\n",
    "\n",
    "def vocab_decode(array, vocab):\n",
    "    return ''.join([vocab[x - 1] for x in array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = string.printable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file = open(DATA_PATH, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = unidecode.unidecode(open(DATA_PATH, encoding='utf-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5315132"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    text = re.sub('[^\\w ]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract We consider the learning task consisting in predicting as well as the best function in a finite reference set G up to the smallest possible additive term. If R(g) denotes the generalization error of a prediction function g, under reasonable assumptions on the loss function (typically satisfied by the least square loss when the output is bounded), it is known that the progressive mixture rule ĝ satisfies (1) ER(ĝ) ≤ ming∈G R(g) + Cst log |G| , n '"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract We consider the learning task consisting in predicting as well as the best function in a finite reference set G up to the smallest possible additive term If Rg denotes the generalization error of a prediction function g under reasonable assumptions on the loss function typically satisfied by the least square loss when the output is bounded it is known that the progressive mixture rule g satisfies 1 ERg  mingG Rg  Cst log G  n '"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner(aa[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Character to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 36\n",
      " 37\n",
      " 38\n",
      " 13\n",
      " 14\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 6 (GPU 4)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = vocab.index(string[c])\n",
    "    return Variable(tensor).cuda(4)\n",
    "\n",
    "print(char_tensor('ABCdef'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Chunk into input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer\n",
    "### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size,hidden_size,num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input, hidden,cell):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden,cell\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(num_layers,batch_size,hidden_size)).cuda(4)\n",
    "        cell = Variable(torch.zeros(num_layers,batch_size,hidden_size)).cuda(4)\n",
    "        return hidden,cell\n",
    "model = RNN(n_characters, hidden_size, n_characters, num_layers).cuda(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_str = \"A\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden,cell = model.init_hidden()\n",
    "    x = inp\n",
    "    print(start_str,end=\"\")\n",
    "    for i in range(500):\n",
    "        output,hidden,cell = model(x,hidden,cell)\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = vocab[top_i]\n",
    "        print(predicted_char,end=\"\")\n",
    "        x = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Variable containing:\n",
      " 4.5692\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "*Gy\f",
      "+e.|VS-A??.Cz\f",
      "_]\\4cqSTq9VA+:^H*{CwneGFFrqkT5r%lU-6)5\f",
      "M#\tWCb9glM~y#IRl`HmHL}q3Z*\u000b",
      "}0f'0c;qUP4*(\u000b",
      "?'LelCo\u000b",
      "6LN2^,zoPE:W>/\t!CC+M@GxYNyaTq)!]X=jx<r\\8{} .cte)GMCa)oPKEK5e\"LF%aA%!sPN&#39?2^r`3h 9Gqj\f",
      "9]T__b\f",
      "s?bB.l'%'\n",
      "\n",
      "X@\n",
      " VS?\n",
      "_s!BtFz+egA*R\\dpeju))'o'<T9/8\f",
      "U\t $^_S;2MRa\f",
      "11fJ%Mi]70QfwyEwl;vkV\\:=9>\"bt\f",
      "of80',_wH7N/1t[`jRjWud|vd6G\n",
      "Kufvq3MOqNhb{ZI*}8)u\u000b",
      "pu`@upe/d\\,273d)C-u\"u\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.3731\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Aban on as ferih of and tethm oseninatr inen imanptiche an ald treutwiro tingra wares int dethalh al leye an os ach th and Mesuer an Cnisekrniobtner prodels of as th aco Ith anict hescon Ta e amte tro+ al inssin fg sliticsine ing 1aly one sinb tosv mof in ons apinsting alemang ithes acts anuthlors sapriof fitugus the in din onUtce istis eso the idine parnetat con ararodt ans arecolined th ans eden yced hinin gebcage thpen inpin whor rin csectred oracomal then fand ing ion Tre carinis ager fa tar \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.1816\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstrasstration Der an in cuceniselorinte se oacect actration sti2arin palle cfon bact nusyul nallexs onlatis prking aramssif We proing fonem Abing os edendimatol the s a ifproth ch Matidion eaterion comest the polationg ans raterict rematore ppaled an velale staend coad Winleal mamatiction Pre thasil the surolinles ans coscuturiin caterd The iond the ine the thieal turocating of comesal torater respedem ramats aled aritiwion chiy al re the stion we thie of conten nearota onatize the tiatialge c \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.7849\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abtract emace suthe datan th copat ing cor the in sictornilcorcactive Por cacurpactid ing thed an a proly ination ghor praatigunt assisforl pancent cemantornicag to densing delpation Tho ue nea n in thamiminchebtining maprompiais can boare thove dafis a ippone dearle prasesis efsive deled Cqichse vegrecule nemcaue thition monint se cestrean mannin arprond sty striniom che tely a fur es tra izinctes ation nonengiivre spactald the dess armion thach calum the serm indcis int suvaes cuonction onsincl\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0000\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstrac We condetramise vedoparnation fissuliziming delact deutredata nonsisiffor dedel deso funct of the stertion prozime logem of for a mowf of concmince domes annrabog chechibes prineclal a pporive a deurion ghat wion thognation sintal dinecstiation prithe by vit uctecting of for bindatys hedection aplein dectifes aning dypralie monveation exetia prodetricing pribitian that the stimstion monser mits in praces cond sys st ssion ase parebs rearnoby in earrition and can ballar intion a nvect cont\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 2.0070\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract mastintenting of lelerance in nestite of sucivace as conchepe sintim andymatial of the binear cosube prom susio consion an in consions a inatise sof w thor cutanive conerasce ardaingem of by in comeus of icting by is the renetrition earning heapprobe wormimed a noat ter weritize stasing exule to matpate sentaret ator Misty setationod pritem onesiglge neditation corithcre satere the ined but inde wenere sublich controce leule leation ating thetrith epreactrom nenledes beenction the agcos \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.8681\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We setwork of stictith Noal aeveres an We seble ristenting 2nvet angentatire cumpre an clanysesiting contrations We thod inffoxibate benen codel preontribe Sepablting thictatermating coman fone of ayen dewed undernt recunting the rechine oruming stlativeye rect fornt a sesed there peralw is on colled the sethity the prealy sing Veres is ble huse unmation istrom meat limentanmtial thing of We sations Ke ulgesets stanithm ow collastion ony the simulbition insert anly betires renectiongorni\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.9354\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We sof contwor by the conserse inclis intrabilled is the praily the and beth in pralliqulitiont setic the a presuis use bes speellgent of croble Thazed the be approih mation suctiont lissir vandent orpationed enlan netrion this systing dores in of infork inforfationd ust the sporks reding proectatured at inforing wely sinage a rated the rechorseg aly a indatench capers of roted dectaral madenemer the be a soprewal it a cofnorustig on inullex a setipall thot putecion the andy and thes sfo\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5508\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract in modex on We caper learntrical alforallem of probased wistractions obstsimatoristive netunt of on shent prodem the pap copting uning aly ent genentoous and estiun manking lit such bear a fheand denconding in is thoder the qural renetate stane valuling mearge fient of of thificuned Hera modulizension ar ove exchich probitions a of at a and promes hoprole to of iffor appromaths us odelgigning potricys it aypurite hamporal stunting proplem lor the shblem be difuels of eLpr nete of convect\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.6408\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We introimitiong at the an aand eachis i an of mascisio moder or syst a note an mol a fuctions for numplic intwle on metranication algoriation mabe the a promemign ive ofs I prestrabsibast to wiwith formenal probiart extrimiting tre happresed of in in and Xactes a fivic  senation is mavedy the expritims for with typer slite proposate learn resical masipall proming cors erexproring distring methe of agrializinith wicing anve with inined its anplies of the cral sentic is to a consive twith\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.8458\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract The regred and a prompesed famens ext the newses hare the modele a vesture learnes or is netivence loculdent have erfonment from odevery mumporess a derent a fre on is meaters in of appropedical nessing the in erentactor and on ferace of puront to raberabite of consicy the the unale for funted form opporks SA thes and indssic shown impled lewhe approused loon the roparing pare for the neural networs formode presical wical partaice ofnearames of dixy dis ainghes of the ry with that treach\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.6215\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract Ys of the straintically moperoperical networmmirge can hinalysed sences inferass 3or mownow or the cally the inffience and the stribled archive semplion the sension whe midilele hoces wrach this pricitrices wy the subettic preproling the prored varisimation anal ancoworet interning ination algorith networl introdic station of learning perror decation In to stable of consire for ble a vinating himed to combled fraction the in infor approbsion with SP as ury for ly and appropabine used bee\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.7706\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We connineat ondom unthes of computation of elabilize numbises a propeass whe Ulgenteral stimal cost cansian the MIs usedated or the the compurain varinal compuent restance networks intreact withm the inve to interal networks stimate explet in to semal the Conmangorodive the as fon thenes of exputide the conterfor spets in cashatio groblem the comportired strancy the uncet cognaling proxing networks consents an gradization daty in the problem aver a the conver of the evections a has prob\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.6914\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract A an a Netrialc the and a computer applicate a multance by the enpents part learning meakes of nonchical the by setor a novalloovalit destroch offernical stor condence with stork a spacent prove the setant of lon the stow and stoxical rear consstract of timent to the for the scan for and infearn and real dechistiated by for for entes is a spect to a nof low that and a spicisual methods We retreduch is module condevel partade and pithm Thiw mand ntater porew of to pare a feation algoratar\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5854\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract We rection is in to retrod can contence in extricy modililal learning sets chenear and as probase proce a such scoldeling the seble nonstroded ast malles of rentic aption of dixing fans a classipe Dis muters from the encorsts the Pinined pative proap learn intricunal stamel which in leant that Galing beth codite of lear in to disility to a for We consisted a dypens problem tre a in exuper intern the models of promeviment and a nearnorithms and in conting simutions Proder whe deach a o in\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.8582\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract Colel fant approaching ipting former a shuch Codel for infearal has regrach basing decon bother expical the shoper the ards betive data an a sevial on leare a notwo the vithe from feern inver implew is bous the dequent comply a modend for bear introxtem and painalized cost deast machical sygmation to a clear thes comporimator problems vifients the reprecorally are and calbisional gramived to contadised systicies wormodel sy the miskan vivective refiesed can explection compitions refor th\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5949\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract The progation whigative setwenes Bys iners of sechowe the and prodsional porling propical sturation in a precting for propose is poter thever ussibution use a sparks stame of paper and a boon algorithm the in the prepsection leeffine mations traintic prament assummatsed belex maining as imporning of aglear beret for provised apargain of to litiallork is uses with learning in a computive offecties the for neural instration We and sets in for arve neural propose an bre a new som is wloo ge\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5641\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We conter a nowo for is are as postical bee or problem of high The rating a ssumble struct the nearal a a sling botive network computations is for by between probsem in the gralies of this model clase can approcess in and lassed a nonceneratation model algoration a eformation distrre tering is instruct of accipuce rered accriment adurand of this bes of from is agormensions for we problem the consingly lear rearce and extrithm neang to Hfichise bhich on the the seting suver bely this stra\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.6603\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We describle to solutes such exalises in the sparate part propostif in the percied filts a compset compution of the the models gorancal the stoint the soin for onulition optorking apprach approrninionted we in stripicaly of undernenture majore and alomen the pased as ween of model of the process In the to erectronn many cass prome the peduch caures and that boenal with and mumensian beter neuropar fictoring boden is in to a which arch segroces of part this vesporks Hown itunity In the re\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.4162\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We pooal precent to parts of learning sting eister infromsio on the conperoble poperantic basegroit of the mopoxized and hig with action algoritistate the mangorithened betry addles work out progoister agoporization anctiols usteration purallent to one problem of clustrof 3menores the maphine of Distropuin with the computation diChar distering in interent the exporition In recuprovios beth empisturic strougple noneral noul proboritity large propensive of genovel station are movely consiq\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.3146\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We preser of ry stuch that and trand the manchent In frample thef opt which computally MAMIn is ter descresith a neural depent recomporvementales ass of the experois sceple interform for from mothis fimed to stal to Camake a neural spective metraction labels for repreder approcally for method proplems for PA alus whre the space model a Seterns firing relew invendepts Metrach invarial cost is ixtreding a Blassian proportabed problems to distributuration infeed equertations on thoring mais\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5115\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We method ty sisting implication for in the decisity and particued extractional of the method problem divecticual lowir model work for are resuppenoge of the many inderse as algorithm pocess from is quated station problem approximations systicis are bus been has ofter a natiditing metworks the unplations with analysize RL PCAn heven of this a reintrocome subserred Suplitered been bether a drequegendence algorithm aries in thid is a base fologation meaters of partime are in the a new that\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.7864\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract In the structive singlizestich complensionally generaluly of reghievend lased studured thes dechision work of neural nomporate the repronse a for neurometed deccorge is the from one optept to paralicate learning in thadeformate singming fired and that in thodeled the now try such requairal maparove bothes condind inincension pronting data neurormation data paper intected forly compution a gausuin is K spequive introints functes propose sider the large restwous for the infesence of the by\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5917\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract The neural providence to extrical rement and by a constades In this problem a sective a stactive of the a drased and the model learning an ilgmerational probleming to invel of dicassed parting the distadives that a par metiat deent data constribution learning is trimized from been to and the macollel lean provise partical on in a concent to an himmel Blonvariable entractive fronconsion of stated with the model classing an eamention of the specent from be general distcection algent algosi\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5505\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We porect bricized of the depents of the algent part task the mote sepex the wad popert a leaursting evelection of eftenents of the neural know the problem a models alguring the data a staptional for 2nochasting are cont on seperal reventurated a proves Many a simple problem to eficlelthobural hitems problems sof this to dimplent and wellcorge Formentives clas the efformanilative neural caesed are an an and to isploden plext problem of diminal model of the means for this In postrates of \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.5147\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We fint the learn of this and betry deprom the madely of theira of a interformations intract for of correrse an a nonal models on and thely rank of thee app the detevent and form inferent is cant tirst the study consider approach framework of agnorm achignce of the exterd to addire condiant SVM a restity classifies problem In thve setrox out a spertional model stable inalugure and love is invisuation imples of restry diformowerform For a model ardient sof a noder of a Quarding to chase a\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.3058\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "ABSTRACT PRe encalized arave in the dormational stully compicaral classifications are is The sucher the to contractalk for model the reminears stative poscies based on such bodent of exproximation computations the require by are sumitharning the is MM a vary learning a superof simples of the model is of the classification an Joncisly postic a complensty to show imension ovel rartine explial infering in a generalize signalitic the classignal cincares of methods in a Rinthered from chamilitions the\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.4424\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract This stately model distric inforal respactionformaning to muliension and Carloling networks beaning that a nonwing an enterformation eximily of inven graphy for undertional nulobatue and remain new and contist the network dicharing approach the generaling with desyming we we classy to constrates achigmation exent proposes be are in of use modelology usened betwork to simploition efficiention of a new gormation atdits and relage a and inference algorithm eximallic model the based are behi\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.0757\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract We present many opties in in the respection of reconter of a have of the feed verior metas ag the wel us object feed the a covinlo autimbametricate that main the addiction schal and numbets of sefset computal rescalowic for is retise label mains the bering systication allyible abjecting algorithm neuring sequencion in we introduces is heargemes and problem as estimity be based recoblem of proxing completrogution dafing and is Beverges that distributions is is the prestical and We propere\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.8499\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We propesion frame problem as a motia listical on a probled Pur combing to method maximum multic clund boulting reistables aveses is is an assignieve aing propose to used the problems of an and these faplite the consupered with dimines trated by the onlumation problem We imagation madilitions is achiewer probables proder and refully maction which lear of shoog the sooper to be postimation tran are in and between considem on descive dificts Gissguge recontly setant visuloging for actions \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.2692\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We present rast vepric optsion soments and constriact a camelous and map problems unpurate and models in the online samples to eptorimaning in the decensions recoputation to the struct multilishation matual spices a novels rangions anter when thats are facke starientral dre node of a convential distariance of this resogul or neural which the of nonite sognith dighbres Thin the shows genelabling factions a motelogant an are instrogure problem on model divequents of the beounint condition \n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.2856\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract This problem bosed on the informants underning the among declide a spechine of the data scele the module and we the numberving Hackproble the sceres aring batived Nurumal paper conline type a neural renures highe consinding and stunds artive of labeled on dynamics conside contral theourvality intraines with interactive fears and the problem data using inditritifications for deal functive algorithm probabilisted in the spuce method are the stater as meanalysing have large these method fap\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.3387\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We introce VC a compinel Monddor analysis Colling neural lagelel the shocally interaction assumpleation frameworks the as such algority convers when excent stare corkproactes to is algorithms modelled on discribution use Markov statistems wheren constaters assmestic destral relater a scension is cased uss riximes to the contastical have are anying for extersical spemewerasetting for lated typose analyzes Prexe a selace in supervelation mefinatary analysion clowncricces with a new paper c\n",
      "\n",
      "\n",
      "\n",
      " Variable containing:\n",
      " 1.0883\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 4)]\n",
      " \n",
      "\n",
      "Abstract We provide propaberde Deloper of sample of evalies algorithms in but a neural on basemets and tamets We shover a general straction of the for a Markov can filing of oulfersed MSNNN expertial models a such sequendent bo Markonkon the pabitrial functional learning matull massified when based based for boocal sensing setch for connections ruptical to is generative neural spole tration for on use the method the sequed to classure on invellyy In the complearith decentrate monsing archic contr\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-6d11b451a375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    total = char_tensor(cleaner(data[random.randint(0,len(data))]))\n",
    "    inp = total[:-1]\n",
    "    label = total[1:]\n",
    "    hidden,cell = model.init_hidden()\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inp[j]\n",
    "        y_ = label[j]\n",
    "        y,hidden,cell = model(x,hidden,cell)\n",
    "        loss += loss_func(y,y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
    "        test()\n",
    "        print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
